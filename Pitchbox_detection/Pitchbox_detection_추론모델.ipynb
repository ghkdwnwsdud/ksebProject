{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 피치 트래커 (Pitch tracker box) 여부를 판별하는 Classification model 추론\n",
        "- name: 남기범\n",
        "- project: 야구 AI 캐스터\n",
        "- stack: roboflow (1.1.34), tensorflow (2.15.0), cv2 (4.8.0), numpy (1.25.2)"
      ],
      "metadata": {
        "id": "oMvPPXHBGiNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 활용한 라이브러리 목록 및 버전\n",
        "roboflow==1.1.34\n",
        "tensorflow==2.15.0\n",
        "cv2==4.8.0\n",
        "numpy==1.25.2"
      ],
      "metadata": {
        "id": "OFRreTeBKTDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추론모델: Real-time detection"
      ],
      "metadata": {
        "id": "dEeOLxmUV-3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10번째 프레임마다 모델에 넣어 판별하도록 변경 (프레임별 연산시간 20~40 ms)\n",
        "# 판별 결과 Pitchbox가 있는지 없는지 판정 (probability > 0.95)\n",
        "# Pitchbox가 있다고 연속 3번 판정하면 1, 아니면 0을 출력\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def detect_pitch_tracker(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the frame rate of the video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Analyze every 10th frame\n",
        "        if frame_count % 10 == 0:\n",
        "            # Preprocess the frame for the model\n",
        "            resized_frame = cv2.resize(frame, (224, 224))\n",
        "            input_tensor = np.expand_dims(resized_frame, axis=0) / 255.0\n",
        "\n",
        "            # Perform classification\n",
        "            prediction = model.predict(input_tensor, verbose=0)\n",
        "\n",
        "            # Determine the result based on the prediction\n",
        "            if prediction[0] > 0.95:\n",
        "                result = 1\n",
        "            else:\n",
        "                result = 0\n",
        "\n",
        "            # Print result for real-time verification\n",
        "            print(result)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "QzDXxSMIbdWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('best_model_dataset_5_test_1.0.h5')\n",
        "# Path to your input video file\n",
        "video_path = 'videoplayback_360p.mp4'\n",
        "\n",
        "detect_pitch_tracker(video_path)"
      ],
      "metadata": {
        "id": "qB1md7rKYrdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 검증: (Tracker ON = 1, OFF =0) 인 프레임들 각각 모아서 영상으로 저장"
      ],
      "metadata": {
        "id": "lITb0zf8ZJR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('best_model_dataset_5_test_1.0.h5')\n",
        "# Path to your input video file\n",
        "video_path = 'videoplayback_360p.mp4'\n",
        "\n",
        "\n",
        "def detect_pitch_tracker_verbose(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the frame rate of the video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    frame_count = 0\n",
        "    result_frames = []  # List to store frames with result 1\n",
        "    non_result_frames = []  # List to store frames with result 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Analyze every 10th frame\n",
        "        if frame_count % 10 == 0:\n",
        "            # Preprocess the frame for the model\n",
        "            resized_frame = cv2.resize(frame, (224, 224))\n",
        "            input_tensor = np.expand_dims(resized_frame, axis=0) / 255.0\n",
        "\n",
        "            # Perform classification\n",
        "            prediction = model.predict(input_tensor, verbose=0)\n",
        "\n",
        "            # Determine the result based on the prediction\n",
        "            if prediction[0] > 0.95:\n",
        "                result = 1\n",
        "                # Store the frame with result 1\n",
        "                result_frames.append(frame)\n",
        "            else:\n",
        "                result = 0\n",
        "                # Store the frame with result 0\n",
        "                non_result_frames.append(frame)\n",
        "\n",
        "            # Print result for real-time verification\n",
        "            print(result)\n",
        "\n",
        "            # Log the frame processing time\n",
        "            end_time = time.time()\n",
        "            processing_time = end_time - start_time\n",
        "            print(f\"Frame {frame_count}: Processing time = {processing_time:.4f} seconds\")\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Save the frames with result 1 to a video file\n",
        "    if result_frames:\n",
        "        height, width, layers = result_frames[0].shape\n",
        "        out = cv2.VideoWriter('pitch_tracker_detected.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "        for frame in result_frames:\n",
        "            out.write(frame)\n",
        "        out.release()\n",
        "        print(\"Saved frames with result 1 to pitch_tracker_detected.mp4\")\n",
        "\n",
        "    # Save the frames with result 0 to a video file\n",
        "    if non_result_frames:\n",
        "        height, width, layers = non_result_frames[0].shape\n",
        "        out = cv2.VideoWriter('pitch_tracker_not_detected.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "        for frame in non_result_frames:\n",
        "            out.write(frame)\n",
        "        out.release()\n",
        "        print(\"Saved frames with result 0 to pitch_tracker_not_detected.mp4\")\n",
        "\n",
        "detect_pitch_tracker_verbose(video_path)"
      ],
      "metadata": {
        "id": "x71wfQswbgPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사용 라이브러리 및 환경 정리"
      ],
      "metadata": {
        "id": "_lreuno9Km99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 활용한 라이브러리 목록 및 버전\n",
        "# 최종 추론모델에선 google.colab 불필요\n",
        "roboflow==1.1.34\n",
        "tensorflow==2.15.0\n",
        "cv2==4.8.0\n",
        "numpy==1.25.2\n",
        "# google.colab==1.0.0"
      ],
      "metadata": {
        "id": "WjrkWxMdIcV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "AllZn5ZNHfhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 참고 링크"
      ],
      "metadata": {
        "id": "D2-Dhnbzg-Pp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roboflow 프로젝트 링크: https://app.roboflow.com/2024ksebpitchboxdetection/pitchbox_classification/1/export\n",
        "\n",
        "Youtube URL 파일로 다운로드: https://ssyoutube.com/ko34aM/youtube-video-downloader"
      ],
      "metadata": {
        "id": "gATl9evPhAU3"
      }
    }
  ]
}